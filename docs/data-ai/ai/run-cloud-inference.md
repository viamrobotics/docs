---
linkTitle: "Run inference in the cloud"
title: "Run inference in the cloud"
weight: 55
layout: "docs"
type: "docs"
modulescript: true
aliases:
description: "Run inference in the cloud using an ML model."
---

Cloud inference enables you to run machine learning models in the Viam cloud, instead of on a local machine. This gives you access to:

- more computational resources
- faster inference times
- larger models

Some use cases require more powerful ML models than you can run on your machines. In other situations, you may not need to run ML models on edge devices at all. Cloud inference enables you to run inference on synced data using powerful hardware in the cloud.

## Choose an ML model

You can run inference using any Tensorflow model in the Viam registry, including private models within your own organization.

## Run inference on an image
